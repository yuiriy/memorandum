{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE（平均平方二乗誤差）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5531726674375732\n"
     ]
    }
   ],
   "source": [
    "#真の値と予測値の差の二乗の平均の平方根\n",
    "#MAEより外れ値の影響を受けやすいため、あらかじめ外れ値のを除く処理をしたほうが良い\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "#y_trueが真の値、y_predが予測値\n",
    "y_true = [1.0, 1.5, 2.0, 1.2, 1.8]\n",
    "y_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17032547044118188\n"
     ]
    }
   ],
   "source": [
    "#真の値と予測値の対数をそれぞれとった後の差の事情の平方根\n",
    "#目的変数が裾の重い分布を持ち、変換しないままだと大きな値の影響が強い場合や、真の値と予測値の比率に着目したい場合に用いられる。この指標は比率に着目している。\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "#y_trueが真の値、y_predが予測値\n",
    "y_true = [1.0, 1.5, 2.0, 1.2, 1.8]\n",
    "y_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n",
    "\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "print(rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33999999999999997\n"
     ]
    }
   ],
   "source": [
    "#真の値と予測値の差の絶対値の平均\n",
    "#MAEは外れ値の影響を低減した形での評価に適した関数\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#y_trueが真の値、y_predが予測値\n",
    "y_true = [1.0, 1.5, 2.0, 1.2, 1.8]\n",
    "y_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 決定係数（$ R^2 $）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2499999999999996\n"
     ]
    }
   ],
   "source": [
    "#回帰分析の当てはまりの良さを表す\n",
    "#この指標を最大化することはRMSEを最小化することと同意\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#y_trueが真の値、y_predが予測値\n",
    "y_true = [1.0, 1.5, 2.0, 1.2, 1.8]\n",
    "y_pred = [0.8, 1.5, 1.8, 1.3, 3.0]\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二値分類における評価指標〜正例か負例かを予測値とする場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列 (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1]\n",
      " [2 2]]\n",
      "[[2 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#0,1で表される二値分類の真の値と予測値\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "tp = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 1))\n",
    "tn = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 0))\n",
    "fp = np.sum((np.array(y_true) == 0) & (np.array(y_pred) == 1))\n",
    "fn = np.sum((np.array(y_true) == 1) & (np.array(y_pred) == 0))\n",
    "\n",
    "confusion_matrix1 = np.array([[tp, fp],[fn, tn]])\n",
    "\n",
    "print(confusion_matrix1)\n",
    "\n",
    "#sckit-learnのmetricsモジュールのconfusion_matrixでも作成できるが、混同行列の要素の配置が違うので注意が必要\n",
    "confusion_matrix2 = confusion_matrix(y_true, y_pred)\n",
    "print(confusion_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy（正答率）とerror rate（誤答率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "#accuracyは予測が正しい割合、error rateは誤っている割合\n",
    "#不均衡のデータの場合は特にモデルの性能を評価しづらい\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#0,1で表される二値分類の真の値と予測値\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# precision（適合率）とrecall（再現率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "#precisionは正例と予測したもののうち真の値も正例の割合、recallは真の値が正例のもののうちどの程度を正例の予測として含めることができているかの割合\n",
    "#それぞれ0から1の値を取り、1に近づくほど良いスコア\n",
    "#precisionとrecallはどちらかの値を高くしようとするともう一方の値は低くなる\n",
    "#誤検知を少なくしたい場合はprecisionを重視し、正例の見逃しを避けたい場合はrecallを重視する\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#0,1で表される二値分類の真の値と予測値\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "precision = precision_score(y_true, y_pred)\n",
    "print(precision)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-scoreとFβ-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666665\n",
      "0.6833333333333332\n"
     ]
    }
   ],
   "source": [
    "#F1-scoreはprecisionとrecallの調和平均で計算される指標\n",
    "#Fβ-scoreはF1-scoreからrecallとprecisionのバランスをrecallをどれだけ重視するかを表す係数βによって調整した指標\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "#0,1で表される二値分類の真の値と予測値\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f1)\n",
    "fbeta = fbeta_score(y_true, y_pred, 0.8)\n",
    "print(fbeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCC（Matthews Correlation Coefficient）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2581988897471611\n"
     ]
    }
   ],
   "source": [
    "#不均衡なデータに対してモデルの性能を適切に評価しやすい指標\n",
    "#-1から+1の範囲をとり、+1の時に完璧な予測、0の時にランダムな予測、-1の時に完全に反対の予測を行なっている\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#0,1で表される二値分類の真の値と予測値\n",
    "y_true = [1, 0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 0, 1, 1, 0, 0, 1, 1]\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "print(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二値分類における評価指標〜正例である確率を予測値とする場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7135581778200728\n"
     ]
    }
   ],
   "source": [
    "#真の値を予測している確率の対数を取り、符号を反転させている\n",
    "#低いほうが良い指標\n",
    "#そのレコードが正例である確率を低く予測したにも関わらず負例である場合や、正例である確率を高く予測したにも関わらず負例である場合にペナルティが大きく与えられる\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#0,1で表される二値分類の真の値と予測値\n",
    "y_true = [1, 0, 1, 1, 0, 1]\n",
    "y_prob = [0.1, 0.2, 0.8, 0.8, 0.1, 0.3]\n",
    "\n",
    "logloss = log_loss(y_true, y_prob)\n",
    "print(logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC（Area Under the ROC Curve）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "#ROC曲線が描く曲線をもとに計算される\n",
    "#完全な予測を行なった場合AUCは1.0, ランダムな予測の場合AUCは0.5程度となる\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#0,1で表される二値分類の真の値と予測値\n",
    "y_true = [1, 0, 1, 1, 0, 1]\n",
    "y_prob = [0.1, 0.2, 0.8, 0.8, 0.1, 0.3]\n",
    "\n",
    "auc = roc_auc_score(y_true, y_prob)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 他クラス分類における評価指標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
